{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQpr1Eu0kWlM"
      },
      "outputs": [],
      "source": [
        "!pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "dktuvqywmESe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import Stemmer, Lemmatizer"
      ],
      "metadata": {
        "id": "DCa17GwwkbXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemme = Stemmer()\n",
        "stemme.stem(\"گلستان\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p_bwn8GBkqJ0",
        "outputId": "85b2a0eb-6598-42fe-84b9-b9c4d4e392f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'گلس'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemm = Lemmatizer()\n",
        "lemm.lemmatize(\"می‌روم\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-jo8M3m7k0co",
        "outputId": "881f57c4-fe76-42f2-a976-4fb3487663f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'رفت#رو'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "NYhsMF0-lays"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"popular\")"
      ],
      "metadata": {
        "id": "7xUn4e01mQ-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import *"
      ],
      "metadata": {
        "id": "k37bsUEmmTvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "IR9wkozlo9xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemm = PorterStemmer()"
      ],
      "metadata": {
        "id": "CBCxh9B0na12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemm.stem(\"writing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eyKZewKAnerh",
        "outputId": "4ca1be65-67ae-438f-8e8d-4e9796ccceed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'write'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"NLTK has PorterStemmer class with the help of which we can easily implement Porter Stemmer algorithms for the word we want to stem. This class knows several regular word forms and suffixes with the help of which it can transform the input word to a final stem. The resulting stem is often a shorter word having the same root meaning. Let us see an example\""
      ],
      "metadata": {
        "id": "v7KoZIDJnhKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemm = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "qnR0Bt1kp278"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(txt)\n",
        "sentences"
      ],
      "metadata": {
        "id": "T6zcOWcln7v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in sentences:\n",
        "  word_tokens = [lemm.lemmatize(w) for w in word_tokenize(s) if w not in stopwords.words(\"english\")]\n",
        "  print(word_tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "ROvyBK0oonaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "7Z-QAPWZq1KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls /root/nltk_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGXsoy-zq_CS",
        "outputId": "aa42d135-4fbf-43c0-f2ba-2d6c41cf404c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mchunkers\u001b[0m/  \u001b[01;34mgrammars\u001b[0m/  \u001b[01;34mmisc\u001b[0m/    \u001b[01;34msentiment\u001b[0m/  \u001b[01;34mtaggers\u001b[0m/\n",
            "\u001b[01;34mcorpora\u001b[0m/   \u001b[01;34mhelp\u001b[0m/      \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mstemmers\u001b[0m/   \u001b[01;34mtokenizers\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s in sentences:\n",
        "  word_tokens = [lemm.lemmatize(w) for w in word_tokenize(s) if w not in stopwords.words(\"english\")]\n",
        "  print(word_tokens)"
      ],
      "metadata": {
        "id": "pWHR4w4jql-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}