{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4bf041-f710-4a6c-ab74-cb74e51f553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f84933-dfeb-4632-8326-66e2ec7f31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"MapsaBigData\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0629bd62-cdb2-405a-9899-9a6af0d791ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "filePath = \"\"\"./databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet\"\"\"\n",
    "\n",
    "airbnbDF = spark.read.parquet(filePath)\n",
    "\n",
    "(trainDF, testDF) = airbnbDF.randomSplit([.8, .2], seed=42)\n",
    "\n",
    "categoricalCols = [field for (field, dataType) in trainDF.dtypes if dataType == \"string\"]\n",
    "\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid=\"skip\")\n",
    "\n",
    "numericCols = [field for (field, dataType) in trainDF.dtypes if ((dataType == \"double\") & (field != \"price\"))]\n",
    "\n",
    "assemblerInputs = indexOutputCols + numericCols\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "rf = RandomForestRegressor(labelCol=\"price\", maxBins=40, maxDepth=5, numTrees=100, seed=42)\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer, vecAssembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285a8531-b813-42e7-a656-955f0634bd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-1.28.0-py3-none-any.whl (17.0 MB)\n",
      "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.4.40)\n",
      "Requirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.4)\n",
      "Collecting gunicorn<21\n",
      "  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: packaging<22 in /opt/conda/lib/python3.10/site-packages (from mlflow) (21.3)\n",
      "Requirement already satisfied: alembic<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.8.1)\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Using cached sqlparse-0.4.2-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<5,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (4.11.4)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.28.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (8.1.3)\n",
      "Collecting prometheus-flask-exporter<1\n",
      "  Using cached prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pandas<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.4.3)\n",
      "Requirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.9.0)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Using cached databricks_cli-0.17.3-py3-none-any.whl\n",
      "Collecting Flask<3\n",
      "  Using cached Flask-2.2.2-py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.20.1)\n",
      "Requirement already satisfied: cloudpickle<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.1.0)\n",
      "Collecting docker<6,>=4.0.0\n",
      "  Using cached docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.0)\n",
      "Requirement already satisfied: pytz<2023 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2022.2.1)\n",
      "Collecting querystring-parser<2\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Using cached GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic<2->mlflow) (1.2.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.4.0)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker<6,>=4.0.0->mlflow) (1.3.3)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.10/site-packages (from Flask<3->mlflow) (3.1.2)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/conda/lib/python3.10/site-packages (from gunicorn<21->mlflow) (65.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<5,>=3.7.0->mlflow) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<22->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2->mlflow) (2.8.2)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from prometheus-flask-exporter<1->mlflow) (0.14.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (1.26.11)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<2,>=1.4.0->mlflow) (1.1.2)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.0->Flask<3->mlflow) (2.1.1)\n",
      "Installing collected packages: Werkzeug, tabulate, sqlparse, smmap, querystring-parser, itsdangerous, gunicorn, gitdb, Flask, docker, databricks-cli, prometheus-flask-exporter, gitpython, mlflow\n",
      "Successfully installed Flask-2.2.2 Werkzeug-2.2.2 databricks-cli-0.17.3 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 itsdangerous-2.1.2 mlflow-1.28.0 prometheus-flask-exporter-0.20.3 querystring-parser-1.2.4 smmap-5.0.0 sqlparse-0.4.2 tabulate-0.8.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6e4b4f2-1c29-4d75-bb23-2b21bf4791d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "import pandas as pd\n",
    "\n",
    "with mlflow.start_run(run_name=\"linear-regression\") as run:\n",
    "    # Log params: num_trees and max_depth\n",
    "    mlflow.log_param(\"num_trees\", rf.getNumTrees())\n",
    "    mlflow.log_param(\"max_depth\", rf.getMaxDepth())\n",
    "    # Log model\n",
    "    pipelineModel = pipeline.fit(trainDF)\n",
    "    mlflow.spark.log_model(pipelineModel, \"model\")\n",
    "    # Log metrics: RMSE and R2\n",
    "    predDF = pipelineModel.transform(testDF)\n",
    "    regressionEvaluator = RegressionEvaluator(predictionCol=\"prediction\",\n",
    "    labelCol=\"price\")\n",
    "    rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
    "    r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
    "    mlflow.log_metrics({\"rmse\": rmse, \"r2\": r2})\n",
    "    # Log artifact: feature importance scores\n",
    "    rfModel = pipelineModel.stages[-1]\n",
    "    pandasDF = (pd.DataFrame(list(zip(vecAssembler.getInputCols(),\n",
    "    rfModel.featureImportances)),\n",
    "    columns=[\"feature\", \"importance\"])\n",
    "    .sort_values(by=\"importance\", ascending=False))\n",
    "    # First write to local filesystem, then tell MLflow where to find that file\n",
    "    pandasDF.to_csv(\"feature-importance.csv\", index=False)\n",
    "    mlflow.log_artifact(\"feature-importance.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
