{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_dog_cat.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, pathlib\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "TBxtF2JqC6GX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC_itNecAosk"
      },
      "outputs": [],
      "source": [
        "from google.colab import files \n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "oBUzi_vMA6h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "jyY2FgCbA7wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugVq-qaZBB0i",
        "outputId": "fe663843-b411-4f7a-cd11-bb51c8882689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 98% 793M/812M [00:05<00:00, 170MB/s]\n",
            "100% 812M/812M [00:05<00:00, 145MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq dogs-vs-cats.zip"
      ],
      "metadata": {
        "id": "YXx85F-rD28D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq train.zip"
      ],
      "metadata": {
        "id": "FY5iHmrGEd_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")"
      ],
      "metadata": {
        "id": "cKNZIn3fFQc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_subset(subset_name, start_index, end_index): \n",
        "  for category in (\"cat\", \"dog\"):\n",
        "    dir = new_base_dir / subset_name / category\n",
        "    os.makedirs(dir)\n",
        "    fnames = [f\"{category}.{i}.jpg\"\n",
        "                for i in range(start_index, end_index)]\n",
        "    for fname in fnames:\n",
        "      shutil.copyfile(src=original_dir / fname,\n",
        "                                 dst=dir / fname)\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ],
      "metadata": {
        "id": "yQP17gtkGTW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) \n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "vT86lLnPHKzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb43S--BHPvh",
        "outputId": "a0bdfd01-4c6a-4623-e349-7a579c510aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 178, 178, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 89, 89, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 87, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 43, 43, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 9, 9, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 12545     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 991,041\n",
            "Trainable params: 991,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "RtX2PCaqHgQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Data preprocessing]\n",
        "1 Read the picture files.<br/>\n",
        "2 Decode the JPEG content to RGB grids of pixels.</br>\n",
        "3 Convert these into floating-point tensors.<br/>\n",
        "4 Resize them to a shared size (we’ll use 180 × 180)<br/>\n",
        "5 Pack them into batches (we’ll use batches of 32 images).</br>"
      ],
      "metadata": {
        "id": "x0RMuJtSHx3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdgKbwymHpCT",
        "outputId": "f4480ac2-5adc-4279-c3a4-ba81f2215ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data_batch, labels_batch in train_dataset:\n",
        "  print(data_batch)\n",
        "  print(labels_batch)\n",
        "  break"
      ],
      "metadata": {
        "id": "Aexte2MnI9BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "            filepath=\"convnet_from_scratch.keras\",\n",
        "            save_best_only=True,\n",
        "            monitor=\"val_loss\")\n",
        "]"
      ],
      "metadata": {
        "id": "lK-iWjn1J7z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "            train_dataset,\n",
        "            epochs=5,\n",
        "            validation_data=validation_dataset,\n",
        "            callbacks=callbacks)"
      ],
      "metadata": {
        "id": "d3ox3CqOKT_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\") \n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\") \n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\") \n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\") \n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T6yWzfESKXun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using data augmentation and Dropout to mitigate overfitting**"
      ],
      "metadata": {
        "id": "_npkDCoE-0fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define a data augmentation stage to add to an image model\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "      [\n",
        "          layers.RandomFlip(\"horizontal\"),\n",
        "          layers.RandomRotation(0.1),\n",
        "          layers.RandomZoom(0.2),\n",
        "      ]\n",
        ")"
      ],
      "metadata": {
        "id": "PEXIJBj2_ieK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a new convnet that includes image augmentation and dropout\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "4pr7cwuwAZg2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "            keras.callbacks.ModelCheckpoint(\n",
        "                      filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "                      save_best_only=True,\n",
        "                      monitor=\"val_loss\")\n",
        "          ]\n",
        "history = model.fit(\n",
        "            train_dataset,\n",
        "            epochs=100,\n",
        "            validation_data=validation_dataset,\n",
        "            callbacks=callbacks)"
      ],
      "metadata": {
        "id": "uneJRDnNAjzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer learning(Leveraging a pretrained model)**"
      ],
      "metadata": {
        "id": "Eo5zy1pQBBEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction with a pretrained model\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "TCH9ld0VBp1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Instantiating the VGG16 convolutional base\n",
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "                                      weights=\"imagenet\",\n",
        "                                      include_top=False,\n",
        "                                      input_shape=(180, 180, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgPZYbueBrRv",
        "outputId": "99225452-43dc-4062-b1c0-ac8448fb3a1c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3PtAaRPCJBy",
        "outputId": "1026f033-c32a-4b92-fff6-f224ba635a57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FAST FEATURE EXTRACTION WITHOUT DATA AUGMENTATION\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cRVx2aZdCf8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features_and_labels(dataset):\n",
        "  all_features = []\n",
        "  all_labels = []\n",
        "  for images, labels in dataset:\n",
        "    preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
        "    features = conv_base.predict(preprocessed_images)\n",
        "    all_features.append(features)\n",
        "    all_labels.append(labels)\n",
        "  return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "\n",
        "train_features, train_labels = get_features_and_labels(train_dataset)\n",
        "val_features, val_labels = get_features_and_labels(validation_dataset)\n",
        "test_features, test_labels = get_features_and_labels(test_dataset)"
      ],
      "metadata": {
        "id": "K2FLRAyiCM7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "                filepath=\"feature_extraction.keras\",\n",
        "                save_best_only=True,\n",
        "                monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "              train_features, train_labels,\n",
        "              epochs=20,\n",
        "              validation_data=(val_features, val_labels),\n",
        "              callbacks=callbacks)"
      ],
      "metadata": {
        "id": "J90LZ6R5DSCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "                                      weights=\"imagenet\",\n",
        "                                      include_top=False)\n",
        "conv_base.trainable = False"
      ],
      "metadata": {
        "id": "4SYZIcVYD3JN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEATURE EXTRACTION TOGETHER WITH DATA AUGMENTATION\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "itwTgG1-Dwpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "qY1SjsiqD_Wq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "          optimizer=\"rmsprop\",\n",
        "          metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "SbkoV-V1EKh0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "                filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
        "                save_best_only=True,\n",
        "                monitor=\"val_loss\")\n",
        "]"
      ],
      "metadata": {
        "id": "Gc6YVPa2EaP9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "                train_dataset,\n",
        "                epochs=50,\n",
        "                validation_data=validation_dataset,\n",
        "                callbacks=callbacks)"
      ],
      "metadata": {
        "id": "GljNpvRVEePm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fine-tuning a pretrained model**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Yhg2fx84Htu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Freezing all layers until the fourth from the last\n",
        "conv_base.trainable = True\n",
        "for layer in conv_base.layers[:-4]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "xsxTjj96Hvjj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "          optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
        "          metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "                  filepath=\"fine_tuning.keras\",\n",
        "                  save_best_only=True,\n",
        "                  monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "              train_dataset,\n",
        "              epochs=30,\n",
        "              validation_data=validation_dataset,\n",
        "              callbacks=callbacks)"
      ],
      "metadata": {
        "id": "jup9JQcTIYKH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"fine_tuning.keras\")\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "IoPXgx3QIeCr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}